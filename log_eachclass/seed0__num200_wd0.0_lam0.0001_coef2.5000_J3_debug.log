[24.8738265  16.30566716 25.16547203 23.62076283 22.15883017 24.15024042
 22.79814482 21.36577368 24.00197983 21.63897514]
    batch_train_loss: 2.3164, original=2.3164, J3=0.0931
    batch_train_loss: 2.3188, original=2.3188, J3=0.0919
    batch_train_loss: 2.3130, original=2.3130, J3=0.0856
    batch_train_loss: 2.3141, original=2.3141, J3=0.0945
    batch_train_loss: 2.3210, original=2.3210, J3=0.0961
    batch_train_loss: 2.3298, original=2.3298, J3=0.0956
    batch_train_loss: 2.3187, original=2.3187, J3=0.0916
    batch_train_loss: 2.3086, original=2.3086, J3=0.0885
    batch_train_loss: 2.3054, original=2.3054, J3=0.0870
    batch_train_loss: 2.3196, original=2.3196, J3=0.0908
    batch_train_loss: 2.3189, original=2.3189, J3=0.0930
    batch_train_loss: 2.3058, original=2.3058, J3=0.0848
    batch_train_loss: 2.3149, original=2.3149, J3=0.0930
    batch_train_loss: 2.3142, original=2.3142, J3=0.0917
    batch_train_loss: 2.3090, original=2.3090, J3=0.0905
    batch_train_loss: 2.3137, original=2.3137, J3=0.0903
    batch_train_loss: 2.3108, original=2.3108, J3=0.0925
    batch_train_loss: 2.3097, original=2.3097, J3=0.0887
    batch_train_loss: 2.3047, original=2.3047, J3=0.0878
    batch_train_loss: 2.3072, original=2.3072, J3=0.0869
(num=200,lam=0.0001,coef=2.5)epoch=0, trainloss=2.314, testloss=['2.351', '2.265', '2.252', '2.374', '2.302', '2.351', '2.277', '2.239', '2.292', '2.267'], testacc=['0.000', '25.198', '9.787', '0.000', '0.000', '0.000', '0.104', '85.603', '0.205', '5.253']
    batch_train_loss: 2.3049, original=2.3049, J3=0.0873
    batch_train_loss: 2.3065, original=2.3065, J3=0.0875
    batch_train_loss: 2.3057, original=2.3057, J3=0.0868
    batch_train_loss: 2.3055, original=2.3055, J3=0.0891
    batch_train_loss: 2.3034, original=2.3034, J3=0.0937
    batch_train_loss: 2.3083, original=2.3083, J3=0.0926
    batch_train_loss: 2.3079, original=2.3079, J3=0.0934
    batch_train_loss: 2.3070, original=2.3070, J3=0.0925
    batch_train_loss: 2.2970, original=2.2970, J3=0.0976
    batch_train_loss: 2.2975, original=2.2975, J3=0.0909
    batch_train_loss: 2.3006, original=2.3006, J3=0.0943
    batch_train_loss: 2.2966, original=2.2966, J3=0.0915
    batch_train_loss: 2.3036, original=2.3036, J3=0.0852
    batch_train_loss: 2.3036, original=2.3036, J3=0.0953
    batch_train_loss: 2.2936, original=2.2936, J3=0.0884
    batch_train_loss: 2.2987, original=2.2987, J3=0.0911
    batch_train_loss: 2.2990, original=2.2990, J3=0.0858
    batch_train_loss: 2.2922, original=2.2922, J3=0.0849
    batch_train_loss: 2.2939, original=2.2939, J3=0.0970
    batch_train_loss: 2.2930, original=2.2930, J3=0.0825
(num=200,lam=0.0001,coef=2.5)epoch=1, trainloss=2.301, testloss=['2.315', '2.277', '2.242', '2.349', '2.284', '2.337', '2.265', '2.238', '2.264', '2.257'], testacc=['0.000', '9.604', '43.314', '0.000', '1.935', '0.000', '2.192', '84.533', '4.620', '29.931']
    batch_train_loss: 2.2956, original=2.2956, J3=0.0958
    batch_train_loss: 2.2897, original=2.2897, J3=0.0940
    batch_train_loss: 2.2911, original=2.2911, J3=0.0942
    batch_train_loss: 2.2876, original=2.2876, J3=0.0940
    batch_train_loss: 2.2872, original=2.2872, J3=0.0916
    batch_train_loss: 2.2911, original=2.2911, J3=0.0923
    batch_train_loss: 2.2864, original=2.2864, J3=0.0849
    batch_train_loss: 2.2926, original=2.2926, J3=0.0933
    batch_train_loss: 2.2846, original=2.2846, J3=0.0933
    batch_train_loss: 2.2859, original=2.2859, J3=0.0894
    batch_train_loss: 2.2844, original=2.2844, J3=0.0815
    batch_train_loss: 2.2852, original=2.2852, J3=0.0736
    batch_train_loss: 2.2829, original=2.2829, J3=0.0941
    batch_train_loss: 2.2799, original=2.2799, J3=0.0902
    batch_train_loss: 2.2857, original=2.2857, J3=0.0939
    batch_train_loss: 2.2806, original=2.2806, J3=0.0865
    batch_train_loss: 2.2918, original=2.2918, J3=0.0927
    batch_train_loss: 2.2788, original=2.2788, J3=0.0888
    batch_train_loss: 2.2792, original=2.2792, J3=0.0932
    batch_train_loss: 2.2839, original=2.2839, J3=0.0877
(num=200,lam=0.0001,coef=2.5)epoch=2, trainloss=2.286, testloss=['2.265', '2.277', '2.227', '2.324', '2.273', '2.337', '2.249', '2.236', '2.244', '2.244'], testacc=['0.918', '10.308', '67.733', '0.000', '7.332', '0.000', '8.664', '73.833', '36.961', '62.834']
    batch_train_loss: 2.2842, original=2.2842, J3=0.0909
    batch_train_loss: 2.2732, original=2.2732, J3=0.0913
    batch_train_loss: 2.2728, original=2.2728, J3=0.0936
    batch_train_loss: 2.2791, original=2.2791, J3=0.0839
    batch_train_loss: 2.2782, original=2.2782, J3=0.0966
    batch_train_loss: 2.2653, original=2.2653, J3=0.0911
    batch_train_loss: 2.2765, original=2.2765, J3=0.0876
    batch_train_loss: 2.2756, original=2.2756, J3=0.0895
    batch_train_loss: 2.2696, original=2.2696, J3=0.0880
    batch_train_loss: 2.2681, original=2.2681, J3=0.0754
    batch_train_loss: 2.2701, original=2.2701, J3=0.0922
    batch_train_loss: 2.2628, original=2.2628, J3=0.0877
    batch_train_loss: 2.2652, original=2.2652, J3=0.0909
    batch_train_loss: 2.2700, original=2.2700, J3=0.0935
    batch_train_loss: 2.2698, original=2.2698, J3=0.0916
    batch_train_loss: 2.2707, original=2.2707, J3=0.0894
    batch_train_loss: 2.2737, original=2.2737, J3=0.0952
    batch_train_loss: 2.2640, original=2.2640, J3=0.1009
    batch_train_loss: 2.2620, original=2.2620, J3=0.0929
    batch_train_loss: 2.2657, original=2.2657, J3=0.0966
(num=200,lam=0.0001,coef=2.5)epoch=3, trainloss=2.271, testloss=['2.228', '2.277', '2.219', '2.292', '2.264', '2.325', '2.227', '2.230', '2.222', '2.231'], testacc=['45.204', '10.308', '65.310', '1.188', '12.322', '0.000', '35.595', '67.802', '79.671', '74.331']
    batch_train_loss: 2.2531, original=2.2531, J3=0.0939
    batch_train_loss: 2.2666, original=2.2666, J3=0.0979
    batch_train_loss: 2.2564, original=2.2564, J3=0.0947
    batch_train_loss: 2.2587, original=2.2587, J3=0.0824
    batch_train_loss: 2.2594, original=2.2594, J3=0.0913
    batch_train_loss: 2.2599, original=2.2599, J3=0.0966
    batch_train_loss: 2.2604, original=2.2604, J3=0.0913
    batch_train_loss: 2.2536, original=2.2536, J3=0.0973
    batch_train_loss: 2.2594, original=2.2594, J3=0.0900
    batch_train_loss: 2.2578, original=2.2578, J3=0.0887
    batch_train_loss: 2.2590, original=2.2590, J3=0.0945
    batch_train_loss: 2.2526, original=2.2526, J3=0.0859
